{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-01T17:55:29.225964Z","iopub.execute_input":"2021-11-01T17:55:29.226542Z","iopub.status.idle":"2021-11-01T17:55:34.918188Z","shell.execute_reply.started":"2021-11-01T17:55:29.226451Z","shell.execute_reply":"2021-11-01T17:55:34.917259Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndata = pd.read_csv('/kaggle/input/did-it-rain-in-seattle-19482017/seattleWeather_1948-2017.csv') \ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:55:34.919620Z","iopub.execute_input":"2021-11-01T17:55:34.919877Z","iopub.status.idle":"2021-11-01T17:55:35.003709Z","shell.execute_reply.started":"2021-11-01T17:55:34.919847Z","shell.execute_reply":"2021-11-01T17:55:35.002942Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"### We need to drop particular columns, that we don't need. \n- Date, but we shall extract day, month and year instead\n- PRCP (otherwise it would be a cheating)\n","metadata":{}},{"cell_type":"code","source":"#1. Drop the PRCP\ndata=data.drop([\"PRCP\"],axis=1)\n\n# 2 Converting object into datetime to extract day, month and year\nfrom datetime import datetime\ndata[\"DATE\"]=pd.to_datetime(data[\"DATE\"], format= \"%Y-%m-%d\")\n\n# Extract day, month and year\ndata[\"DAY\"]=data[\"DATE\"].dt.day\ndata[\"MONTH\"]=data[\"DATE\"].dt.month\ndata[\"YEAR\"]=data[\"DATE\"].dt.year\ndata=data.drop([\"DATE\"], axis=1)\n\n#Rearrange columns\ndata=data[[\"DAY\", \"MONTH\", \"YEAR\", \"TMAX\", \"TMIN\", \"RAIN\"]]\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:55:35.004881Z","iopub.execute_input":"2021-11-01T17:55:35.005175Z","iopub.status.idle":"2021-11-01T17:55:35.055604Z","shell.execute_reply.started":"2021-11-01T17:55:35.005144Z","shell.execute_reply":"2021-11-01T17:55:35.054707Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data.tail()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:55:35.058008Z","iopub.execute_input":"2021-11-01T17:55:35.058350Z","iopub.status.idle":"2021-11-01T17:55:35.069373Z","shell.execute_reply.started":"2021-11-01T17:55:35.058300Z","shell.execute_reply":"2021-11-01T17:55:35.068538Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"x=data.iloc[:,:-1].values\ny=data.iloc[:,-1].values","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:55:35.070917Z","iopub.execute_input":"2021-11-01T17:55:35.071389Z","iopub.status.idle":"2021-11-01T17:55:35.082615Z","shell.execute_reply.started":"2021-11-01T17:55:35.071349Z","shell.execute_reply":"2021-11-01T17:55:35.081699Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Encoding ","metadata":{}},{"cell_type":"code","source":"#Label Encoding for RAIN column\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ny=le.fit_transform(y)\ny","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:55:35.083746Z","iopub.execute_input":"2021-11-01T17:55:35.084262Z","iopub.status.idle":"2021-11-01T17:55:35.214724Z","shell.execute_reply.started":"2021-11-01T17:55:35.084222Z","shell.execute_reply":"2021-11-01T17:55:35.213945Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Splitting the dataset for Training and Test set","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:55:35.216287Z","iopub.execute_input":"2021-11-01T17:55:35.216755Z","iopub.status.idle":"2021-11-01T17:55:35.271616Z","shell.execute_reply.started":"2021-11-01T17:55:35.216711Z","shell.execute_reply":"2021-11-01T17:55:35.270856Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"##  Feature Scaling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nss=StandardScaler()\nx_train=ss.fit_transform(x_train)\nx_test=ss.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:55:35.272953Z","iopub.execute_input":"2021-11-01T17:55:35.273339Z","iopub.status.idle":"2021-11-01T17:55:35.285319Z","shell.execute_reply.started":"2021-11-01T17:55:35.273296Z","shell.execute_reply":"2021-11-01T17:55:35.284524Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Building the ANN","metadata":{}},{"cell_type":"code","source":"# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n\n# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 5))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n\n# Adding the third hidden layer\nclassifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(x_train, y_train, batch_size = 10, epochs = 100)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T18:13:44.658574Z","iopub.execute_input":"2021-11-01T18:13:44.658865Z","iopub.status.idle":"2021-11-01T18:19:34.522153Z","shell.execute_reply.started":"2021-11-01T18:13:44.658832Z","shell.execute_reply":"2021-11-01T18:19:34.521216Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Prediction: ","metadata":{}},{"cell_type":"markdown","source":"- Day : 16\n- Month: 11\n- Year: 1992\n- TMAX:54\n- TMIN: 30\n","metadata":{}},{"cell_type":"code","source":"ann.predict(ss.transform([[16,11,1992,54,30]]))>0.5\n","metadata":{"execution":{"iopub.status.busy":"2021-11-01T18:02:25.842533Z","iopub.execute_input":"2021-11-01T18:02:25.842818Z","iopub.status.idle":"2021-11-01T18:02:25.903662Z","shell.execute_reply.started":"2021-11-01T18:02:25.842789Z","shell.execute_reply":"2021-11-01T18:02:25.902785Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Predicting the test set results","metadata":{}},{"cell_type":"code","source":"y_pred=ann.predict(x_test)\ny_pred=(y_pred>0.5)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","metadata":{"execution":{"iopub.status.busy":"2021-11-01T18:02:29.666143Z","iopub.execute_input":"2021-11-01T18:02:29.667031Z","iopub.status.idle":"2021-11-01T18:02:29.895521Z","shell.execute_reply.started":"2021-11-01T18:02:29.666983Z","shell.execute_reply":"2021-11-01T18:02:29.894189Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Present Confusion Matrix and Accuracy Score","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm=confusion_matrix(y_test, y_pred)\ncm","metadata":{"execution":{"iopub.status.busy":"2021-11-01T18:02:32.826685Z","iopub.execute_input":"2021-11-01T18:02:32.826998Z","iopub.status.idle":"2021-11-01T18:02:32.856275Z","shell.execute_reply.started":"2021-11-01T18:02:32.826965Z","shell.execute_reply":"2021-11-01T18:02:32.855424Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T18:02:36.642602Z","iopub.execute_input":"2021-11-01T18:02:36.642875Z","iopub.status.idle":"2021-11-01T18:02:36.649944Z","shell.execute_reply.started":"2021-11-01T18:02:36.642846Z","shell.execute_reply":"2021-11-01T18:02:36.649291Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Graphs","metadata":{}},{"cell_type":"code","source":"from pylab import rcParams\n\nrcParams['figure.figsize'] = 8, 4\nplt.barh(ML_name, ML_accuracy, color = 'purple')\nplt.xlabel('Accuracy Score', fontsize = '14')\nplt.ylabel('Machine Learning Algorithms', fontsize = '14')\nplt.xlim([0.7, 0.84])\nplt.show()\n#code is taken from here: https://www.kaggle.com/ehsaner/predicting-seattle-rain-part-2","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:55:36.861796Z","iopub.status.idle":"2021-11-01T17:55:36.862158Z","shell.execute_reply.started":"2021-11-01T17:55:36.861985Z","shell.execute_reply":"2021-11-01T17:55:36.862008Z"},"trusted":true},"execution_count":null,"outputs":[]}]}